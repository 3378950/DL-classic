{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_class) -> None:\n",
    "        super().__init__()\n",
    "        # Conv layer\n",
    "        self.conv = nn.Sequential(\n",
    "            # kernel: (in_dim x 11 x 11)\n",
    "            nn.Conv2d(\n",
    "                # the channel size\n",
    "                in_channels=in_dim,\n",
    "                out_channels=96,\n",
    "                kernel_size=11, \n",
    "                stride=4,\n",
    "                padding=0\n",
    "            ),\n",
    "            # feature map: (in_dim x 227 x 227) -> (96 x 55 x 55)\n",
    "\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True),\n",
    "            # parms: nn.MaxPool2d(kernel_size, stride)\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # feature map: (96 x 55 x 55) -> (96 x 27 x 27)\n",
    "\n",
    "            # kernel: (96 x 256 x 256)\n",
    "            nn.Conv2d(96, 256, 5, stride=1, padding=2),\n",
    "            # feature map: (96 x 27 x 27) -> (256 x 27 x 27)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # feature map: (256 x 27 x 27) -> (256 x 13 x 13)\n",
    "\n",
    "            # kernel: (384 x 3 x 3)\n",
    "            nn.Conv2d(256, 384, 3, stride=1, padding=1),\n",
    "            # feature map: (256 x 13 x 13) -> (384 x 13 x 13)\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # kernel: (384 x 3 x 3)\n",
    "            nn.Conv2d(384, 384, 3, stride=1, padding=1),\n",
    "            # feature map: (384 x 13 x 13) -> (384 x 13 x 13)\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # kernel: (256 x 3 x 3)\n",
    "            nn.Conv2d(384, 256, 3, stride=1, padding=1),\n",
    "            # feature map: (384 x 13 x 13) -> (256 x 13 x 13)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "        \n",
    "            nn.MaxPool2d(3, 2)\n",
    "            # feature map: (256 x 13 x 13) -> (256 x 6 x 6)\n",
    "        )\n",
    "        \n",
    "        # full-connective layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)  # (batch,256,6,6) -> (batch,256*6*6)\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "\"\"\"步骤整合 -> 图像增强：\n",
    "    1. 调整图像尺寸（227 x 227)\n",
    "    2. 以0.5的概率水平翻转给定的PIL图像\n",
    "    3. To a tensor\n",
    "\"\"\"\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((227, 227)),\n",
    "    T.RandomHorizontalFlip(0.5),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize((227, 227)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# mnist数据集：0-9的手写数字数据集，训练集60k，测试集10k，类别10，图像：(28x28x1)\n",
    "train_dataset = datasets.MNIST(root=r'data\\mnist',\n",
    "                               train=True,\n",
    "                               transform=train_transform,\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root=r'data\\mnist',\n",
    "                               train=False,\n",
    "                               transform=train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 图像为单通道，有10个类别\n",
    "model = AlexNet(1, 10)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为CPU设置种子用于生成随机数，以使得结果是确定的。\n",
    "torch.manual_seed(1)\n",
    "# 学习率\n",
    "learning_rate = 1e-3\n",
    "# 训练轮数\n",
    "num_epochs = 3\n",
    "# 优化算法Adam = RMSProp + Momentum (梯度、lr两方面优化下降更快更稳)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "# 交叉熵损失函数\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, model):\n",
    "    '''\n",
    "        评估模型预测精度\n",
    "    '''\n",
    "    total = 0\n",
    "    correct = 0 \n",
    "    # 循环内的每个张量都将requires_grad设置为False。当前与当前计算图相连的任何具有梯度的张量现在都与当前图分离。不再能够计算关于这个张量的梯度。\n",
    "    with torch.no_grad():\n",
    "        model.eval() # 评估模式，batchNorm层，dropout层等用于优化训练而添加的网络层会被关闭\n",
    "        for images,labels in data_iter:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # 1 x 10 行向量\n",
    "            _,predicts = torch.max(outputs.data, dim=1) # return: (value, index); dim=1时，按行返回最大值所在索引\n",
    "            total += labels.size(0)\n",
    "            correct += (predicts == labels).cpu().sum()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader=train_loader, optimizer=optimizer, loss_fn=loss_fn, epochs=num_epochs, device=device):\n",
    "    for epoch in range(epochs):\n",
    "        print('current epoch = {}'.format(epoch))\n",
    "        for i,(images,labels) in enumerate(data_loader):\n",
    "            train_accuracy_total = 0\n",
    "            train_correct = 0\n",
    "            train_loss_sum = 0\n",
    "            model.train() # 训练模式，启用batch normalization和dropout \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)   # 计算模型的损失\n",
    "            optimizer.zero_grad()            # 在做反向传播前先清除网络状态\n",
    "            loss.backward()                  # 损失值进行反向传播\n",
    "            optimizer.step()                 # 参数迭代更新\n",
    "\n",
    "            train_loss_sum += loss.item()    # item()返回的是tensor中的值，且只能返回单个值（标量），不能返回向量，使用返回loss等\n",
    "            _,predicts = torch.max(outputs.data, dim=1)  # 输出10类中最大的那个值\n",
    "            train_accuracy_total += labels.size(0)\n",
    "            train_correct += (predicts == labels).cpu().sum().item()\n",
    "        test_acc = evaluate_accuracy(test_loader, model)\n",
    "        print('epoch:{0},   loss:{1:.4f},   train accuracy:{2:.3f},  test accuracy:{3:.3f}'.format(\n",
    "                epoch, train_loss_sum / batch_size, train_correct / train_accuracy_total, test_acc))\n",
    "    print('------------finish training-------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch = 0\n",
      "epoch:0,   loss:0.0079,   train accuracy:0.844,  test accuracy:92.030\n",
      "current epoch = 1\n",
      "epoch:1,   loss:0.0009,   train accuracy:1.000,  test accuracy:95.050\n",
      "current epoch = 2\n",
      "epoch:2,   loss:0.0025,   train accuracy:0.938,  test accuracy:96.670\n",
      "------------finish training-------------\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a16324fbcc06d55f9e20a980762dbdaa491609e11c1edd01cedc38a99826464d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
